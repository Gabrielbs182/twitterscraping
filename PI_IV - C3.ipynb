{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aabb2148",
   "metadata": {},
   "source": [
    "# Projeto Integrador 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85778b25",
   "metadata": {},
   "source": [
    "<img src=\"https://www.faesa.br/hubfs/logo-faesa-branco.png\" style=\"background-color:DarkBlue;width:250px;float:left;\"/>\n",
    "<br><br><br><br><br>\n",
    "<table style=\"float:left;\">\n",
    "    <tr>\n",
    "        <td>\n",
    "            <p><strong>FAESA CENTRO UNIVERSITÁRIO</strong></p>\n",
    "        </td>\n",
    "        <td>\n",
    "            <p></p>\n",
    "        </td>\n",
    "        <td>\n",
    "            <p><strong>Valor:</strong>10,0 (dez) pontos</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <p><strong>Unidade: </strong>Unidade de Computação e Sistemas</p>\n",
    "        </td>\n",
    "        <td>\n",
    "            <p><strong>Curso: </strong>Ciência da Computação e Sistemas de Informação</p>\n",
    "        </td>\n",
    "        <td>\n",
    "            <p></p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <p><strong>Disciplina: </strong>Projeto Integrador Computação IV</p>\n",
    "        </td>\n",
    "        <td>\n",
    "            <p><strong>Professor: </strong>Howard Roatti</p>\n",
    "        </td>\n",
    "        <td>\n",
    "            <p><strong>Nota:</strong>_______________</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <p><strong>Nome dos Integrantes: Gabriel Bremenkamp, Gabriel Tozato, Natan Campos</strong></p>\n",
    "        </td>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008c07af",
   "metadata": {},
   "source": [
    "# Exploração dos dados:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d518ff",
   "metadata": {},
   "source": [
    "## Informações do dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9360e6a8",
   "metadata": {},
   "source": [
    "Dataset se trata de Tweets relacionados as eleições de 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1ea7eb",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "119f24b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns #Lib voltada para plot de graficos, baseada na lib matplotlib\n",
    "import math\n",
    "\n",
    "#Scikit Learn é uma lib open source de aprendizagem de maquina.\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler #Lib voltada a balanceamento de dados\n",
    "from sklearn.model_selection import cross_val_score, RepeatedKFold, train_test_split, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_curve, accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d14a4fa",
   "metadata": {},
   "source": [
    "# Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63808edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ler(a):\n",
    "    resultado = []\n",
    "    if a == 1:\n",
    "        arq = open(\"tweets_valid.txt\",\"r\",encoding=\"utf8\")\n",
    "    else if a==0:\n",
    "        arq = open(\"tweets.txt\",\"r\",encoding=\"utf8\")\n",
    "    linhas = arq.readlines()\n",
    "    for linha in linhas:\n",
    "        resultado.append(linha+'\\t')\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3465a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRANSFORMANDO O DATAFRAME EM UMA MATRIZ DE TERMOS\n",
    "def matrixTweet(df0):\n",
    "    x = np.array(df0['tweets'])\n",
    "    result = []\n",
    "    for i in x:\n",
    "        i2 = i.replace(',','')\n",
    "        i2 = i.replace('.','')\n",
    "        i2 = i.replace(':','')\n",
    "        i2 = i.replace('\\n','')\n",
    "        i2 = i.replace('\\t','')\n",
    "        i2 = i.replace('  ',' ')\n",
    "        i2 = i.split()\n",
    "        result.append(i2)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c92a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metodo que realiza a quantidade de termos por classe\n",
    "def contar_termos(termos, classe):\n",
    "  quant_termos = pd.DataFrame(termos, columns=['Termo'])\n",
    "  quant_termos['Quantidade'] = 0\n",
    "\n",
    "  quant_termo = 0\n",
    "  for termo in termos:\n",
    "    for documento in classe:\n",
    "      if termo in documento:\n",
    "        quant_termo+=1\n",
    "    quant_termos.loc[quant_termos['Termo']==termo, 'Quantidade'] = quant_termo\n",
    "  return quant_termos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f711046",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcular ICF\n",
    "def icfCalc(termo, classe0,classe1,classe2):\n",
    "    Ci = 0\n",
    "    result = 0\n",
    "    C = 3\n",
    "    if termo in classe0:\n",
    "        Ci += 1\n",
    "    if termo in classe1:\n",
    "        Ci += 1\n",
    "    if termo in classe2:\n",
    "        Ci += 1\n",
    "    if Ci == 0:\n",
    "        result = 0\n",
    "    else:\n",
    "        result = math.log(1+(C/Ci))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38a80b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = quantidade de documentos que possuem o termo na classe\n",
    "#b = quantidade de documentos que possuem o termo fora da classe\n",
    "#função: log(2 + a / max(1,b))\n",
    "def relevance_freq(a, b):\n",
    "  return math.log(2 + (a / (max(1,b))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b052351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_por_termo(df, classe_0, classe_1, classe_2):\n",
    "    \n",
    "  classes = [classe_0, classe_1, classe_2]\n",
    "  i = 0\n",
    "  \n",
    "  for classe in classes:\n",
    "    classe_rf = 'Classe_' + str(i)\n",
    "\n",
    "    classe_pertence = classes[0]\n",
    "    classe_nao_pertence_1 = classes[1]\n",
    "    classe_nao_pertence_2 = classes[2]\n",
    "\n",
    "    for termo in df['Termo']:\n",
    "      pertence = int(classe_pertence.loc[quant_termos['Termo']==termo, 'Quantidade'])\n",
    "      nao_pertence = int(classe_nao_pertence_1.loc[quant_termos['Termo']==termo, 'Quantidade'])\n",
    "      nao_pertence += int(classe_nao_pertence_2.loc[quant_termos['Termo']==termo, 'Quantidade'])\n",
    "\n",
    "      rf = relevance_freq(pertence, nao_pertence)\n",
    "\n",
    "      relevancy_frequency.loc[relevancy_frequency['Termo']==termo, classe_rf] = rf\n",
    "    \n",
    "    classe_atual = classes[0]\n",
    "    classe_proxima = classes[1]\n",
    "    classe_ultima = classes[2]\n",
    "    classes[0] = classe_proxima\n",
    "    classes[1] = classe_ultima\n",
    "    classes[2] = classe_atual\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c8e7b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def icfPorTermo(termos, classe_0, classe_1, classe_2,df):\n",
    "    result = []\n",
    "    vlr = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    for termo in termos:\n",
    "        vlr = icfCalc(termo, classe_0,classe_1,classe_2)\n",
    "        result.append(vlr)\n",
    "        \n",
    "    result = np.array(result)\n",
    "    df['Classe_0'] = result\n",
    "    df['Classe_1'] = result\n",
    "    df['Classe_2'] = result\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7dfe9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GERA UM DATAFRAME NOVO USANDO O RESULTADO DO RELEVANCY FREQUENCI AGRUPANDO POR TWEET E USANDO OS TERMOS\n",
    "#COMO COLUNAS\n",
    "\n",
    "def vetorizer(dataframe,dataframePonderacao,relevancy_frequency,classe,classe2):\n",
    "    dfResult = dataframePonderacao\n",
    "    linhas = []\n",
    "    header = []\n",
    "    i=0\n",
    "    for x in dataframe:\n",
    "        linha = []\n",
    "        for column in dfResult:\n",
    "            if column in x:\n",
    "                linha.append(float(relevancy_frequency[classe2].loc[relevancy_frequency['Termo'] == column]))\n",
    "            else:\n",
    "                linha.append(0)\n",
    "        linhas.append(linha)\n",
    "    df = pd.DataFrame(linhas,\n",
    "                  columns = dfResult.columns.values.tolist())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c107672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "\tmodels = list()\n",
    "\tmodels.append(Lasso())\n",
    "\tmodels.append(Ridge())\n",
    "\tmodels.append(DecisionTreeRegressor())\n",
    "\tmodels.append(LinearRegression())\n",
    "\treturn models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c24233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "\tscores = cross_validate(model, df_train_encoded, df_train[outcome], scoring=scoring, cv=kfold, n_jobs=-1)\n",
    "\treturn scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304418b2",
   "metadata": {},
   "source": [
    "##  Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a3f1154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eleições 2022: PDT anuncia apoio a Lula, e Cir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eleições 2022 ou modern family?\\n\\t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O PDT anunciou apoio a Lula no segundo turno ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Simone Tebet pretende encontrar Lula pessoalm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A interpretação é de cada um. Eleições 2022\\n\\t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Um partido, Um candidato não pode sequestrar a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>— Jair Bolsonaro e o presidente do PL, Valdem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Vazou vídeo do Bolsonaro assistindo o Bonner a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>CALMA, XANDÃO! Tô só repassando a notícia da “...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Hoje já podemos dizer que Bolsonaro foi reelei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweets  texto\n",
       "0    Eleições 2022: PDT anuncia apoio a Lula, e Cir...      0\n",
       "1                  eleições 2022 ou modern family?\\n\\t      0\n",
       "2     O PDT anunciou apoio a Lula no segundo turno ...      0\n",
       "3     Simone Tebet pretende encontrar Lula pessoalm...      0\n",
       "4      A interpretação é de cada um. Eleições 2022\\n\\t      0\n",
       "..                                                 ...    ...\n",
       "295  Um partido, Um candidato não pode sequestrar a...      1\n",
       "296   — Jair Bolsonaro e o presidente do PL, Valdem...      1\n",
       "297  Vazou vídeo do Bolsonaro assistindo o Bonner a...      1\n",
       "298  CALMA, XANDÃO! Tô só repassando a notícia da “...      1\n",
       "299  Hoje já podemos dizer que Bolsonaro foi reelei...      1\n",
       "\n",
       "[1300 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Carregando os tweets e convertendo eles para DataFrame\n",
    "txt = ler(1)\n",
    "txtAntigo = ler(0)\n",
    "dfNovo = pd.DataFrame(txt, columns = ['tweets'])\n",
    "dfNovo['texto'] = 1\n",
    "dfAntigo = pd.DataFrame(txtAntigo, columns = ['tweets'])\n",
    "dfAntigo['texto'] = 0\n",
    "df = pd.concat([dfAntigo,dfNovo])\n",
    "df_valid = df.drop_duplicates()\n",
    "df_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a255013",
   "metadata": {},
   "source": [
    "# Classificação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1c732ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando o dataframe em unidimensional para aplicar o vectorizer.\n",
    "x = np.array(df_valid.drop(columns=['texto']))\n",
    "vectorizer = CountVectorizer()\n",
    "flat_x = x.flatten()\n",
    "xVet = vectorizer.fit_transform(flat_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c8f69b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Termo</th>\n",
       "      <th>Quantidade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>útil</td>\n",
       "      <td>5723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5195</th>\n",
       "      <td>únicos</td>\n",
       "      <td>5722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5120</th>\n",
       "      <td>único</td>\n",
       "      <td>5721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>única</td>\n",
       "      <td>5720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3932</th>\n",
       "      <td>últimos</td>\n",
       "      <td>5719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>02</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5509</th>\n",
       "      <td>01</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2367</th>\n",
       "      <td>00hs</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5724 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Termo  Quantidade\n",
       "1002     útil        5723\n",
       "5195   únicos        5722\n",
       "5120    único        5721\n",
       "209     única        5720\n",
       "3932  últimos        5719\n",
       "...       ...         ...\n",
       "2225       02           4\n",
       "5509       01           3\n",
       "2367     00hs           2\n",
       "4796      000           1\n",
       "560        00           0\n",
       "\n",
       "[5724 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Criando um dataframe e ordenando, utilizando as quantidades e os termos como colunas para poder fazer o plot\n",
    "#Deixei os 10 termos que mais se repetem.\n",
    "\n",
    "d = vectorizer.vocabulary_\n",
    "d2 = pd.DataFrame(d.items(), columns=['Termo', 'Quantidade'])\n",
    "df2 = d2.sort_values(by='Quantidade', ascending=False)\n",
    "df2 = df2[df2.Quantidade < 5724]\n",
    "df2\n",
    "dfPonderacao = pd.DataFrame(df2['Termo'])\n",
    "dfPonderacao = dfPonderacao.set_index('Termo')\n",
    "dfPonderacao = dfPonderacao.T\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74421cb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=3, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=3, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=3, random_state=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inicializando a variavel com o Kmeans e treinando o modelo.\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "kmeans.fit(xVet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "036498c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>texto</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eleições 2022: PDT anuncia apoio a Lula, e Cir...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eleições 2022 ou modern family?\\n\\t</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O PDT anunciou apoio a Lula no segundo turno ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Simone Tebet pretende encontrar Lula pessoalm...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A interpretação é de cada um. Eleições 2022\\n\\t</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Um partido, Um candidato não pode sequestrar a...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>— Jair Bolsonaro e o presidente do PL, Valdem...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Vazou vídeo do Bolsonaro assistindo o Bonner a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>CALMA, XANDÃO! Tô só repassando a notícia da “...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Hoje já podemos dizer que Bolsonaro foi reelei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweets  texto  Classification\n",
       "0    Eleições 2022: PDT anuncia apoio a Lula, e Cir...      0               0\n",
       "1                  eleições 2022 ou modern family?\\n\\t      0               0\n",
       "2     O PDT anunciou apoio a Lula no segundo turno ...      0               0\n",
       "3     Simone Tebet pretende encontrar Lula pessoalm...      0               1\n",
       "4      A interpretação é de cada um. Eleições 2022\\n\\t      0               0\n",
       "..                                                 ...    ...             ...\n",
       "295  Um partido, Um candidato não pode sequestrar a...      1               2\n",
       "296   — Jair Bolsonaro e o presidente do PL, Valdem...      1               1\n",
       "297  Vazou vídeo do Bolsonaro assistindo o Bonner a...      1               1\n",
       "298  CALMA, XANDÃO! Tô só repassando a notícia da “...      1               0\n",
       "299  Hoje já podemos dizer que Bolsonaro foi reelei...      1               0\n",
       "\n",
       "[1300 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Incluindo uma nova coluna no dataframe com o nome \"Classification\" que indica a que grupo pertence cada tweet, 0 1 ou 2\n",
    "\n",
    "df['Classification'] = kmeans.labels_\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46dd4703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daqui em diante eu vou plotar graficos correspondentes e termos que mais se repetem em cada grupo.\n",
    "dff = df.drop(columns=['texto'])\n",
    "\n",
    "df0 = dff.loc[df['Classification'] == 0]\n",
    "df1 = dff.loc[df['Classification'] == 1]\n",
    "df2 = dff.loc[df['Classification'] == 2]\n",
    "\n",
    "df0 = df0.drop(columns=['Classification'])\n",
    "df1 = df1.drop(columns=['Classification'])\n",
    "df2 = df2.drop(columns=['Classification'])\n",
    "\n",
    "x0 = np.array(df0)\n",
    "x1 = np.array(df1)\n",
    "x2 = np.array(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8aff1fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Termo</th>\n",
       "      <th>Quantidade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>وها</td>\n",
       "      <td>3663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>ونذكر</td>\n",
       "      <td>3662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>ودعم</td>\n",
       "      <td>3661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>وأعلن</td>\n",
       "      <td>3660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>منه</td>\n",
       "      <td>3659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>من</td>\n",
       "      <td>3658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>لولا</td>\n",
       "      <td>3657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>لحسم</td>\n",
       "      <td>3656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>كانت</td>\n",
       "      <td>3655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>قيادات</td>\n",
       "      <td>3654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>قد</td>\n",
       "      <td>3653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>في</td>\n",
       "      <td>3652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>فعلها</td>\n",
       "      <td>3651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>طلبت</td>\n",
       "      <td>3650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>سيرو</td>\n",
       "      <td>3649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>جومز</td>\n",
       "      <td>3648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>تأييده</td>\n",
       "      <td>3647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>بعض</td>\n",
       "      <td>3646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>اللاتينية</td>\n",
       "      <td>3645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>الجولة</td>\n",
       "      <td>3644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>الثانية</td>\n",
       "      <td>3643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>التنازل</td>\n",
       "      <td>3642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>البرازيل</td>\n",
       "      <td>3641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>البداية</td>\n",
       "      <td>3640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>الانتخابات</td>\n",
       "      <td>3639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>الأولى</td>\n",
       "      <td>3638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>أن</td>\n",
       "      <td>3637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>أمريكا</td>\n",
       "      <td>3636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>útil</td>\n",
       "      <td>3635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1718</th>\n",
       "      <td>única</td>\n",
       "      <td>3634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>último</td>\n",
       "      <td>3633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>últimas</td>\n",
       "      <td>3632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>última</td>\n",
       "      <td>3631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>önemli</td>\n",
       "      <td>3630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>ônibus</td>\n",
       "      <td>3629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>ótimo</td>\n",
       "      <td>3628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3357</th>\n",
       "      <td>ótima</td>\n",
       "      <td>3627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>ódio</td>\n",
       "      <td>3626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>óbvio</td>\n",
       "      <td>3625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3489</th>\n",
       "      <td>índios</td>\n",
       "      <td>3624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3569</th>\n",
       "      <td>ídolo</td>\n",
       "      <td>3623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>ênfase</td>\n",
       "      <td>3622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>época</td>\n",
       "      <td>3621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3535</th>\n",
       "      <td>área</td>\n",
       "      <td>3620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3384</th>\n",
       "      <td>água</td>\n",
       "      <td>3619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>às</td>\n",
       "      <td>3618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3047</th>\n",
       "      <td>zu7c</td>\n",
       "      <td>3617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>zpr</td>\n",
       "      <td>3616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>zonas</td>\n",
       "      <td>3615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>zombavam</td>\n",
       "      <td>3614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Termo  Quantidade\n",
       "1601         وها        3663\n",
       "1612       ونذكر        3662\n",
       "1624        ودعم        3661\n",
       "1606       وأعلن        3660\n",
       "1620         منه        3659\n",
       "1621          من        3658\n",
       "1608        لولا        3657\n",
       "1625        لحسم        3656\n",
       "1618        كانت        3655\n",
       "1615      قيادات        3654\n",
       "1602          قد        3653\n",
       "1609          في        3652\n",
       "1603       فعلها        3651\n",
       "1619        طلبت        3650\n",
       "1604        سيرو        3649\n",
       "1605        جومز        3648\n",
       "1607      تأييده        3647\n",
       "1614         بعض        3646\n",
       "1617   اللاتينية        3645\n",
       "1610      الجولة        3644\n",
       "1611     الثانية        3643\n",
       "1623     التنازل        3642\n",
       "1628    البرازيل        3641\n",
       "1622     البداية        3640\n",
       "1626  الانتخابات        3639\n",
       "1627      الأولى        3638\n",
       "1613          أن        3637\n",
       "1616      أمريكا        3636\n",
       "856         útil        3635\n",
       "1718       única        3634\n",
       "1939      último        3633\n",
       "1047     últimas        3632\n",
       "857       última        3631\n",
       "1312      önemli        3630\n",
       "1650      ônibus        3629\n",
       "804        ótimo        3628\n",
       "3357       ótima        3627\n",
       "616         ódio        3626\n",
       "869        óbvio        3625\n",
       "3489      índios        3624\n",
       "3569       ídolo        3623\n",
       "1756      ênfase        3622\n",
       "1475       época        3621\n",
       "3535        área        3620\n",
       "3384        água        3619\n",
       "284           às        3618\n",
       "3047        zu7c        3617\n",
       "1510         zpr        3616\n",
       "1263       zonas        3615\n",
       "2177    zombavam        3614"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grupo 1 - Nesse grupo se destacam os termos \"Vitória\" \"Vencedor\" \"Vencer\" portanto o classifiquei como Positivo\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "flat_x0 = x0.flatten()\n",
    "x0Vet = vectorizer.fit_transform(flat_x0)\n",
    "\n",
    "d0 = vectorizer.vocabulary_\n",
    "d02 = pd.DataFrame(d0.items(), columns=['Termo', 'Quantidade'])\n",
    "df0 = d02.sort_values(by='Quantidade', ascending=False).head(50)\n",
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4de6bbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grupo 2 - Nesse grupo a pesar de ter um alto numero de termos negativos ele ainda tem uma quantidade menor do que no segundo\n",
    "#grupo, portanto o classifiquei como neutro, pois não tem mais positivos que o primeiro e nem tem mais negativos do que o segundo.\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "flat_x1 = x1.flatten()\n",
    "x1Vet = vectorizer.fit_transform(flat_x1)\n",
    "\n",
    "d1 = vectorizer.vocabulary_\n",
    "d12 = pd.DataFrame(d1.items(), columns=['Termo', 'Quantidade'])\n",
    "df1 = d12.sort_values(by='Quantidade', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3919f7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grupo 3 esse é o grupo ocm maior classificação, tem os maiores termos sendo negativos, \"Odio\" \"Zombam\" \"Zombavam\"\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "flat_x2 = x2.flatten()\n",
    "x2Vet = vectorizer.fit_transform(flat_x2)\n",
    "\n",
    "d2 = vectorizer.vocabulary_\n",
    "d22 = pd.DataFrame(d2.items(), columns=['Termo', 'Quantidade'])\n",
    "df2 = d22.sort_values(by='Quantidade', ascending=False).head(50)\n",
    "df2 = df2[df2.Quantidade < 2939]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1e6bcb",
   "metadata": {},
   "source": [
    "# Ponderações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9c2c1c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando o dataframe em unidimensional para aplicar o vectorizer.\n",
    "\n",
    "flat_x = x.flatten()\n",
    "xVet = vectorizer.fit_transform(flat_x)\n",
    "\n",
    "#Imprimindo todos os termos encontrados no Dataframe.\n",
    "\n",
    "termos = vectorizer.get_feature_names_out()\n",
    "\n",
    "kmeans.fit(xVet)\n",
    "\n",
    "df['Classification'] = kmeans.labels_\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "x_0 = np.array(df['tweets'].loc[df['Classification'] == 0])\n",
    "x_1 = np.array(df['tweets'].loc[df['Classification'] == 1])\n",
    "x_2 = np.array(df['tweets'].loc[df['Classification'] == 2])\n",
    "\n",
    "quant_termos = pd.DataFrame(termos, columns=['Termo'])\n",
    "quant_termos['Quantidade'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ad9b217",
   "metadata": {},
   "outputs": [],
   "source": [
    "classe_0 = contar_termos(termos, x_0)\n",
    "classe_1 = contar_termos(termos, x_1)\n",
    "classe_2 = contar_termos(termos, x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cff86376",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevancy_frequency = pd.DataFrame(termos, columns=['Termo'])\n",
    "relevancy_frequency['Classe_0'] = 0\n",
    "relevancy_frequency['Classe_1'] = 0\n",
    "relevancy_frequency['Classe_2'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d44d666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfIcf = pd.DataFrame(termos, columns=['Termo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f4fea87",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rf_por_termo(relevancy_frequency, classe_0, classe_1, classe_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7f6dde0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNovo = df.loc[df['texto'] == 1]\n",
    "dfAntigo = df.loc[df['texto'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "82725992",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class0 = np.array(d02['Termo'])\n",
    "class1 = np.array(d12['Termo'])\n",
    "class2 = np.array(d22['Termo'])\n",
    "\n",
    "icf = icfPorTermo(dfIcf['Termo'],class0,class1,class2,dfIcf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "da2d3426",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEPARANDO AS MATRIZES POR GRUPO \"CLASSIFICATION\"\n",
    "#novo\n",
    "dfNovo0 = dfNovo.loc[dfNovo['Classification'] == 0]\n",
    "dfNovo0 = matrixTweet(dfNovo0)\n",
    "dfNovo1 = dfNovo.loc[dfNovo['Classification'] == 1]\n",
    "dfNovo1 = matrixTweet(dfNovo1)\n",
    "dfNovo2 = dfNovo.loc[dfNovo['Classification'] == 2]\n",
    "dfNovo2 = matrixTweet(dfNovo2)\n",
    "dfAntigo0 = dfAntigo.loc[dfAntigo['Classification'] == 0]\n",
    "dfAntigo0 = matrixTweet(dfAntigo0)\n",
    "dfAntigo1 = dfAntigo.loc[dfAntigo['Classification'] == 1]\n",
    "dfAntigo1 = matrixTweet(dfAntigo1)\n",
    "dfAntigo2 = dfAntigo.loc[dfAntigo['Classification'] == 2]\n",
    "dfAntigo2 = matrixTweet(dfAntigo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d508929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRF = relevancy_frequency[['Classe_0','Classe_1','Classe_2']]\n",
    "dfICF = dfIcf[['Classe_0','Classe_1','Classe_2']]\n",
    "icfBased = dfICF.mul(dfRF, fill_value = 0)\n",
    "icfBased['Termo'] = dfIcf['Termo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0f8acabc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#antigo\n",
    "dfPonderacaoRF0_antigo = vetorizer(dfAntigo0,dfPonderacao,relevancy_frequency,'Positivo','Classe_0')\n",
    "dfPonderacaoRF1_antigo = vetorizer(dfAntigo1,dfPonderacao,relevancy_frequency,'Neutro','Classe_1')\n",
    "dfPonderacaoRF2_antigo = vetorizer(dfAntigo2,dfPonderacao,relevancy_frequency,'Negativo','Classe_2')\n",
    "dfPonderacaoICF0_antigo = vetorizer(dfAntigo0,dfPonderacao,dfIcf,'Positivo','Classe_0')\n",
    "dfPonderacaoICF1_antigo = vetorizer(dfAntigo1,dfPonderacao,dfIcf,'Neutro','Classe_1')\n",
    "dfPonderacaoICF2_antigo = vetorizer(dfAntigo2,dfPonderacao,dfIcf,'Negativo','Classe_2')\n",
    "dfPonderacaoICFBASED0_antigo = vetorizer(dfAntigo0,dfPonderacao,icfBased,'Positivo','Classe_0')\n",
    "dfPonderacaoICFBASED1_antigo = vetorizer(dfAntigo1,dfPonderacao,icfBased,'Neutro','Classe_1')\n",
    "dfPonderacaoICFBASED2_antigo = vetorizer(dfAntigo2,dfPonderacao,icfBased,'Negativo','Classe_2')\n",
    "#novo\n",
    "dfPonderacaoRF0_novo = vetorizer(dfNovo0,dfPonderacao,relevancy_frequency,'Positivo','Classe_0')\n",
    "dfPonderacaoRF1_novo = vetorizer(dfNovo1,dfPonderacao,relevancy_frequency,'Neutro','Classe_1')\n",
    "dfPonderacaoRF2_novo = vetorizer(dfNovo2,dfPonderacao,relevancy_frequency,'Negativo','Classe_2')\n",
    "dfPonderacaoICF0_novo = vetorizer(dfNovo0,dfPonderacao,dfIcf,'Positivo','Classe_0')\n",
    "dfPonderacaoICF1_novo = vetorizer(dfNovo1,dfPonderacao,dfIcf,'Neutro','Classe_1')\n",
    "dfPonderacaoICF2_novo = vetorizer(dfNovo2,dfPonderacao,dfIcf,'Negativo','Classe_2')\n",
    "dfPonderacaoICFBASED0_novo = vetorizer(dfNovo0,dfPonderacao,icfBased,'Positivo','Classe_0')\n",
    "dfPonderacaoICFBASED1_novo = vetorizer(dfNovo1,dfPonderacao,icfBased,'Neutro','Classe_1')\n",
    "dfPonderacaoICFBASED2_novo = vetorizer(dfNovo2,dfPonderacao,icfBased,'Negativo','Classe_2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ec50bac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Antigo\n",
    "dfPonderacaoRF0_antigo['Classification'] = 'Positivo'\n",
    "dfPonderacaoRF1_antigo['Classification'] = 'Neutro'\n",
    "dfPonderacaoRF2_antigo['Classification'] = 'Negativo'\n",
    "dfPonderacaoICF0_antigo['Classification'] = 'Positivo'\n",
    "dfPonderacaoICF1_antigo['Classification'] = 'Neutro'\n",
    "dfPonderacaoICF2_antigo['Classification'] = 'Negativo'\n",
    "dfPonderacaoICFBASED0_antigo['Classification'] = 'Positivo'\n",
    "dfPonderacaoICFBASED1_antigo['Classification'] = 'Neutro'\n",
    "dfPonderacaoICFBASED2_antigo['Classification'] = 'Negativo'\n",
    "#Novo\n",
    "dfPonderacaoRF0_novo['Classification'] = 'Positivo'\n",
    "dfPonderacaoRF1_novo['Classification'] = 'Neutro'\n",
    "dfPonderacaoRF2_novo['Classification'] = 'Negativo'\n",
    "dfPonderacaoICF0_novo['Classification'] = 'Positivo'\n",
    "dfPonderacaoICF1_novo['Classification'] = 'Neutro'\n",
    "dfPonderacaoICF2_novo['Classification'] = 'Negativo'\n",
    "dfPonderacaoICFBASED0_novo['Classification'] = 'Positivo'\n",
    "dfPonderacaoICFBASED1_novo['Classification'] = 'Neutro'\n",
    "dfPonderacaoICFBASED2_novo['Classification'] = 'Negativo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ffb84e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JUNTANDO TODOS OS DATAFRAMES\n",
    "#Antigo\n",
    "df_valid_RF_antigo = pd.concat([dfPonderacaoRF0_antigo, dfPonderacaoRF1_antigo,dfPonderacaoRF2_antigo])\n",
    "df_valid_ICF_antigo = pd.concat([dfPonderacaoICF0_antigo, dfPonderacaoICF1_antigo,dfPonderacaoICF2_antigo])\n",
    "df_valid_ICFBASED_antigo = pd.concat([dfPonderacaoICFBASED0_antigo, dfPonderacaoICFBASED1_antigo,dfPonderacaoICFBASED2_antigo])\n",
    "#Novo\n",
    "df_valid_RF_novo = pd.concat([dfPonderacaoRF0_novo, dfPonderacaoRF1_novo,dfPonderacaoRF2_novo])\n",
    "df_valid_ICF_novo = pd.concat([dfPonderacaoICF0_novo, dfPonderacaoICF1_novo,dfPonderacaoICF2_novo])\n",
    "df_valid_ICFBASED_novo = pd.concat([dfPonderacaoICFBASED0_novo, dfPonderacaoICFBASED1_novo,dfPonderacaoICFBASED2_novo])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb7195a",
   "metadata": {},
   "source": [
    "# Treinando os modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65c36a9",
   "metadata": {},
   "source": [
    "## Relevancy frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8112235",
   "metadata": {},
   "source": [
    "### KNN - RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dcd72d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7433333333333333"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Definindo uma baseline utilizando KNN\n",
    "baselineKNN_RF = KNeighborsClassifier(n_neighbors=20)\n",
    "\n",
    "#Recebendo o dataset segundo o filtro do random forest\n",
    "X = df_valid_RF_antigo.drop(columns=['Classification'])\n",
    "y = df_valid_RF_antigo['Classification']\n",
    "\n",
    "#Dividindo em treinamento e teste\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "#treinando o modelo\n",
    "baselineKNN_RF.fit(X_train, y_train)\n",
    "\n",
    "#Imprimindo o score\n",
    "predKNN = baselineKNN_RF.predict(X_valid)\n",
    "accuracy_score(y_valid, predKNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2b22e3e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negativo       0.00      0.00      0.00        42\n",
      "      Neutro       0.00      0.00      0.00        35\n",
      "    Positivo       0.74      1.00      0.85       223\n",
      "\n",
      "    accuracy                           0.74       300\n",
      "   macro avg       0.25      0.33      0.28       300\n",
      "weighted avg       0.55      0.74      0.63       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabriel.sebastiao\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\gabriel.sebastiao\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\gabriel.sebastiao\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Pontuação\n",
    "classification = classification_report(y_valid, predKNN)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "002f186f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49333333333333335"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validação\n",
    "\n",
    "#Recebendo o dataset segundo o filtro do random forest\n",
    "X = df_valid_RF_novo.drop(columns=['Classification'])\n",
    "y = df_valid_RF_novo['Classification']\n",
    "\n",
    "#Imprimindo o score\n",
    "predKNN = baselineKNN_RF.predict(X)\n",
    "accuracy_score(y, predKNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397e43db",
   "metadata": {},
   "source": [
    "### Naive Bayes - RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fcb5963d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4066666666666667"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Definindo uma baseline utilizando KNN\n",
    "naiveModel_RF = GaussianNB()\n",
    "\n",
    "#Recebendo o dataset segundo o filtro do random forest\n",
    "X = df_valid_RF_antigo.drop(columns=['Classification'])\n",
    "y = df_valid_RF_antigo['Classification']\n",
    "\n",
    "#Dividindo em treinamento e teste\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "#treinando o modelo\n",
    "naiveModel_RF.fit(X_train, y_train)\n",
    "\n",
    "#Imprimindo o score\n",
    "predNaive = naiveModel_RF.predict(X_valid)\n",
    "accuracy_score(y_valid, predNaive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bc1760e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negativo       0.14      0.45      0.21        42\n",
      "      Neutro       0.31      0.29      0.30        35\n",
      "    Positivo       0.71      0.42      0.53       223\n",
      "\n",
      "    accuracy                           0.41       300\n",
      "   macro avg       0.39      0.39      0.35       300\n",
      "weighted avg       0.58      0.41      0.46       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Pontuação\n",
    "classification = classification_report(y_valid, predNaive)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1d53bb34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3433333333333333"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validação\n",
    "\n",
    "#Recebendo o dataset segundo o filtro do random forest\n",
    "X = df_valid_RF_novo.drop(columns=['Classification'])\n",
    "y = df_valid_RF_novo['Classification']\n",
    "\n",
    "#Imprimindo o score\n",
    "predNaive = naiveModel_RF.predict(X)\n",
    "accuracy_score(y, predNaive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb74e8f",
   "metadata": {},
   "source": [
    "## ICF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ea216b",
   "metadata": {},
   "source": [
    "### KNN - ICF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "95944aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7433333333333333"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Definindo uma baseline utilizando KNN\n",
    "baselineKNN_ICF = KNeighborsClassifier(n_neighbors=20)\n",
    "\n",
    "#Recebendo o dataset segundo o filtro do random forest\n",
    "X = df_valid_ICF_antigo.drop(columns=['Classification'])\n",
    "y = df_valid_ICF_antigo['Classification']\n",
    "\n",
    "#Dividindo em treinamento e teste\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "#treinando o modelo\n",
    "baselineKNN_ICF.fit(X_train, y_train)\n",
    "\n",
    "#Imprimindo o score\n",
    "predKNN = baselineKNN_ICF.predict(X_valid)\n",
    "accuracy_score(y_valid, predKNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bf837e33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negativo       0.00      0.00      0.00        42\n",
      "      Neutro       0.00      0.00      0.00        35\n",
      "    Positivo       0.74      1.00      0.85       223\n",
      "\n",
      "    accuracy                           0.74       300\n",
      "   macro avg       0.25      0.33      0.28       300\n",
      "weighted avg       0.55      0.74      0.63       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabriel.sebastiao\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\gabriel.sebastiao\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\gabriel.sebastiao\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Pontuação\n",
    "classification = classification_report(y_valid, predKNN)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "35699026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4866666666666667"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validação\n",
    "\n",
    "#Recebendo o dataset segundo o filtro do random forest\n",
    "X = df_valid_ICF_novo.drop(columns=['Classification'])\n",
    "y = df_valid_ICF_novo['Classification']\n",
    "\n",
    "#Imprimindo o score\n",
    "predKNN = baselineKNN_ICF.predict(X)\n",
    "accuracy_score(y, predKNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aedf8a4",
   "metadata": {},
   "source": [
    "### Naive Bayes - ICF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d601e92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44333333333333336"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Definindo uma baseline utilizando KNN\n",
    "naiveModel_ICF = GaussianNB()\n",
    "\n",
    "#Recebendo o dataset segundo o filtro do random forest\n",
    "X = df_valid_ICF_antigo.drop(columns=['Classification'])\n",
    "y = df_valid_ICF_antigo['Classification']\n",
    "\n",
    "#Dividindo em treinamento e teste\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "#treinando o modelo\n",
    "naiveModel_ICF.fit(X_train, y_train)\n",
    "\n",
    "#Imprimindo o score\n",
    "predNaive = naiveModel_ICF.predict(X_valid)\n",
    "accuracy_score(y_valid, predNaive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "30c49ec2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negativo       0.20      0.64      0.31        42\n",
      "      Neutro       0.28      0.43      0.34        35\n",
      "    Positivo       0.80      0.41      0.54       223\n",
      "\n",
      "    accuracy                           0.44       300\n",
      "   macro avg       0.43      0.49      0.40       300\n",
      "weighted avg       0.65      0.44      0.48       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Pontuação\n",
    "classification = classification_report(y_valid, predNaive)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9d0b2018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37666666666666665"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validação\n",
    "\n",
    "#Recebendo o dataset segundo o filtro do random forest\n",
    "X = df_valid_ICF_novo.drop(columns=['Classification'])\n",
    "y = df_valid_ICF_novo['Classification']\n",
    "\n",
    "#Imprimindo o score\n",
    "predNaive = naiveModel_ICF.predict(X)\n",
    "accuracy_score(y, predNaive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5ff425",
   "metadata": {},
   "source": [
    "## ICF-BASED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fc27cd",
   "metadata": {},
   "source": [
    "### KNN - ICF-BASED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "999964de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7433333333333333"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Definindo uma baseline utilizando KNN\n",
    "baselineKNN_ICFBASED = KNeighborsClassifier(n_neighbors=20)\n",
    "\n",
    "#Recebendo o dataset segundo o filtro do random forest\n",
    "X = df_valid_ICFBASED_antigo.drop(columns=['Classification'])\n",
    "y = df_valid_ICFBASED_antigo['Classification']\n",
    "\n",
    "#Dividindo em treinamento e teste\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "#treinando o modelo\n",
    "baselineKNN_ICFBASED.fit(X_train, y_train)\n",
    "\n",
    "#Imprimindo o score\n",
    "predKNN = baselineKNN_ICFBASED.predict(X_valid)\n",
    "accuracy_score(y_valid, predKNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8f403384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negativo       0.00      0.00      0.00        42\n",
      "      Neutro       0.00      0.00      0.00        35\n",
      "    Positivo       0.74      1.00      0.85       223\n",
      "\n",
      "    accuracy                           0.74       300\n",
      "   macro avg       0.25      0.33      0.28       300\n",
      "weighted avg       0.55      0.74      0.63       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabriel.sebastiao\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\gabriel.sebastiao\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\gabriel.sebastiao\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Pontuação\n",
    "classification = classification_report(y_valid, predKNN)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0bf7f9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4866666666666667"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validação\n",
    "\n",
    "#Recebendo o dataset segundo o filtro do random forest\n",
    "X = df_valid_ICFBASED_novo.drop(columns=['Classification'])\n",
    "y = df_valid_ICFBASED_novo['Classification']\n",
    "\n",
    "#Imprimindo o score\n",
    "predKNN = baselineKNN_ICF.predict(X)\n",
    "accuracy_score(y, predKNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07acf8fb",
   "metadata": {},
   "source": [
    "### Naive Bayes - ICF-BASED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b511957a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45666666666666667"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Definindo uma baseline utilizando KNN\n",
    "naiveModel_ICFBASED = GaussianNB()\n",
    "\n",
    "#Recebendo o dataset segundo o filtro do random forest\n",
    "X = df_valid_ICFBASED_antigo.drop(columns=['Classification'])\n",
    "y = df_valid_ICFBASED_antigo['Classification']\n",
    "\n",
    "#Dividindo em treinamento e teste\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "#treinando o modelo\n",
    "naiveModel_ICFBASED.fit(X_train, y_train)\n",
    "\n",
    "#Imprimindo o score\n",
    "predNaive = naiveModel_ICFBASED.predict(X_valid)\n",
    "accuracy_score(y_valid, predNaive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9d778101",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negativo       0.17      0.55      0.26        42\n",
      "      Neutro       0.38      0.40      0.39        35\n",
      "    Positivo       0.77      0.45      0.57       223\n",
      "\n",
      "    accuracy                           0.46       300\n",
      "   macro avg       0.44      0.47      0.41       300\n",
      "weighted avg       0.64      0.46      0.50       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Pontuação\n",
    "classification = classification_report(y_valid, predNaive)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "979d5c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37666666666666665"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validação\n",
    "\n",
    "#Recebendo o dataset segundo o filtro do random forest\n",
    "X = df_valid_ICF_novo.drop(columns=['Classification'])\n",
    "y = df_valid_ICF_novo['Classification']\n",
    "\n",
    "#Imprimindo o score\n",
    "predNaive = naiveModel_ICF.predict(X)\n",
    "accuracy_score(y, predNaive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c90d74c",
   "metadata": {},
   "source": [
    "Após treinar os modelos, percebi que a maior pontuação vem do algoritmo de vetorização ICF junto com o modelo KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6a09fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7bdcd9f84821488ca1aefdd5b383dc6099ae3b1ac329612af81525cc197a794"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
